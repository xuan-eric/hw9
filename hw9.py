# -*- coding: utf-8 -*-
"""HW9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ib3jT2gDyVQ8FEt1xKiiF96em5LIdMV4
"""

import torch
print(torch.cuda.is_available())
print(torch.cuda.get_device_name(0))

pip install -U datasets transformers peft accelerate scikit-learn matplotlib

from datasets import load_dataset

dataset = load_dataset("dair-ai/emotion")
print(dataset)

emotion_labels = dataset["train"].features["label"].names
print(emotion_labels)
# ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']
label2emotion = {i: l for i, l in enumerate(emotion_labels)}

risk_map = {
    "joy": 0, "love": 0, "surprise": 0,
    "anger": 1, "fear": 1,
    "sadness": 2,
}

def add_risk(example):
    emo = label2emotion[example["label"]]
    example["risk"] = risk_map[emo]
    return example

dataset = dataset.map(add_risk)

from transformers import AutoTokenizer, AutoModelForSequenceClassification

base_model_name = "bert-base-uncased"

tokenizer = AutoTokenizer.from_pretrained(base_model_name)
model = AutoModelForSequenceClassification.from_pretrained(
    base_model_name,
    num_labels=6  # six emotion labels
)

def tokenize_function(batch):
    return tokenizer(
        batch["text"],
        padding="max_length",
        truncation=True,
        max_length=128
    )

tokenized_datasets = dataset.map(tokenize_function, batched=True)
tokenized_datasets = tokenized_datasets.remove_columns(["text"])
tokenized_datasets = tokenized_datasets.rename_column("label", "labels")

tokenized_datasets.set_format("torch")

emotion_names = ["joy", "love", "surprise", "anger", "fear", "sadness"]

zero_shot_template = """You are a psychologist analyzing social media posts.
Classify the emotion of the following post into exactly one of:
{labels}.

Post: "{text}"

Answer with only the emotion word.
"""

def build_zero_shot_prompt(text):
    return zero_shot_template.format(
        labels=", ".join(emotion_names),
        text=text
    )

few_shot_examples = [
    ("I feel so happy today, everything is perfect!", "joy"),
    ("I miss you so much, my heart hurts.", "sadness"),
    ("You are the love of my life.", "love"),
]

few_shot_template = """You are a psychologist analyzing social media posts.
Below are some example posts and their emotion labels.

{examples}

Now classify the emotion of the following post into exactly one of: {labels}.

Post: "{text}"

Answer with only the emotion word.
"""

def build_few_shot_prompt(text):
    ex_str = "\n".join(
        [f'Post: "{t}" -> {lab}' for t, lab in few_shot_examples]
    )
    return few_shot_template.format(
        examples=ex_str,
        labels=", ".join(emotion_names),
        text=text
    )

import torch

def parse_emotion_from_output(output_text):
    output_text = output_text.lower()
    for emo in emotion_names:
        if emo in output_text:
            return emo
    return "sadness"

def predict_emotion_zero_shot(text, generate_fn):
    prompt = build_zero_shot_prompt(text)
    out = generate_fn(prompt)
    emo = parse_emotion_from_output(out)
    return emo

def predict_emotion_few_shot(text, generate_fn):
    prompt = build_few_shot_prompt(text)
    out = generate_fn(prompt)
    emo = parse_emotion_from_output(out)
    return emo

from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training

lora_config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=["query", "key", "value"],
    lora_dropout=0.05,
    bias="none",
    task_type="SEQ_CLS",
)

model = get_peft_model(model, lora_config)
model.print_trainable_parameters()

import transformers
print(transformers.__version__)
from transformers import TrainingArguments
TrainingArguments.__module__

emotion_labels = dataset["train"].features["label"].names

from transformers import Trainer

def compute_metrics(eval_pred):
    import numpy as np
    from sklearn.metrics import f1_score

    logits, labels = eval_pred
    preds = np.argmax(logits, axis=-1)

    # Emotion F1 (macro)
    f1_emotion = f1_score(labels, preds, average="macro")

    emo2risk_vec = np.vectorize(lambda x: risk_map[emotion_labels[x]])
    y_true_risk = emo2risk_vec(labels)
    y_pred_risk = emo2risk_vec(preds)
    f1_risk = f1_score(y_true_risk, y_pred_risk, average="macro")

    return {
        "f1_emotion_macro": f1_emotion,
        "f1_risk_macro": f1_risk,
    }


trainer.compute_metrics = compute_metrics

import os
os.environ["WANDB_DISABLED"] = "true"

from transformers import TrainingArguments, Trainer

def compute_metrics(eval_pred):
    import numpy as np
    from sklearn.metrics import f1_score

    logits, labels = eval_pred
    preds = np.argmax(logits, axis=-1)

    f1_emotion = f1_score(labels, preds, average="macro")


    emo2risk_vec = np.vectorize(lambda x: risk_map[emotion_labels[x]])
    y_true_risk = emo2risk_vec(labels)
    y_pred_risk = emo2risk_vec(preds)
    f1_risk = f1_score(y_true_risk, y_pred_risk, average="macro")

    return {
        "f1_emotion_macro": f1_emotion,
        "f1_risk_macro": f1_risk,
    }

training_args = TrainingArguments(
    output_dir="./emotion-lora",
    per_device_train_batch_size=32,
    per_device_eval_batch_size=64,
    num_train_epochs=3,
    learning_rate=2e-4,
    logging_steps=100,
    report_to="none",
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

trainer.train()

eval_results = trainer.evaluate(tokenized_datasets["validation"])
print(eval_results)

import torch
from torch.nn.functional import softmax

test_ds = tokenized_datasets["test"]

with torch.no_grad():
    outputs = trainer.predict(test_ds)

logits = outputs.predictions
labels = outputs.label_ids   # emotion (0–5)
preds = np.argmax(logits, axis=-1)

# Emotion → Risk
emo2risk_vec = np.vectorize(lambda x: risk_map[id2label[x]])
y_true_risk = emo2risk_vec(labels)
y_pred_risk = emo2risk_vec(preds)

probs = softmax(torch.tensor(logits), dim=-1).numpy()

idx_sadness = emotion_labels.index("sadness")
p_high_risk = probs[:, idx_sadness]

from sklearn.metrics import (
    f1_score, roc_auc_score, average_precision_score,
    confusion_matrix, classification_report
)
from sklearn.preprocessing import label_binarize

# F1 (多類)
f1_risk_macro = f1_score(y_true_risk, y_pred_risk, average="macro")
print("F1 (risk, macro):", f1_risk_macro)

# AUROC / PR-AUC (多類 one-vs-rest)
y_true_onehot = label_binarize(y_true_risk, classes=[0, 1, 2])

y_true_binary = (y_true_risk == 2).astype(int)  # 1 = high_risk
y_pred_binary = (y_pred_risk == 2).astype(int)

auroc = roc_auc_score(y_true_binary, p_high_risk)
pr_auc = average_precision_score(y_true_binary, p_high_risk)

print("AUROC (high_risk vs others):", auroc)
print("PR-AUC (high_risk vs others):", pr_auc)

# Confusion Matrix（三類 risk）
cm = confusion_matrix(y_true_risk, y_pred_risk, labels=[0,1,2])
print("Confusion Matrix (risk):\n", cm)

print("Classification report (risk):")
print(classification_report(y_true_risk, y_pred_risk, target_names=["low","mid","high"]))

import matplotlib.pyplot as plt
import numpy as np

indices = np.arange(len(p_high_risk))

plt.figure(figsize=(10, 4))
plt.plot(indices, p_high_risk)
plt.xlabel("Post index (test set)")
plt.ylabel("P(high_risk)")
plt.title("High-risk probability over posts")
plt.grid(True)
plt.tight_layout()
plt.show()

window = 50
kernel = np.ones(window) / window
rolling_high = np.convolve(p_high_risk, kernel, mode="valid")

plt.figure(figsize=(10, 2))
plt.imshow(
    rolling_high[np.newaxis, :],
    aspect="auto",
    interpolation="nearest"
)
plt.colorbar(label="Avg P(high_risk)")
plt.yticks([])  # 不需要 y 軸
plt.xlabel("Rolling window position")
plt.title(f"High-risk concentration heatmap (window={window})")
plt.tight_layout()
plt.show()

